#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import os
import sys
import argparse
import datetime
import traceback
import asyncio
import pandas as pd
from sqlalchemy import create_engine, text
import requests
from dotenv import load_dotenv
from playwright.async_api import async_playwright
import os
import tempfile

# –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫—É –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ Playwright –≤ –¥–æ–º–∞—à–Ω–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
TEMP_DIR = os.path.join(os.path.expanduser("~"), ".playwright-tmp")
os.makedirs(TEMP_DIR, exist_ok=True)

# –ü–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª—è–µ–º –≤—Å–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è, –≤–ª–∏—è—é—â–∏–µ –Ω–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
os.environ["PLAYWRIGHT_TMPDIR"] = TEMP_DIR
os.environ["TMPDIR"] = TEMP_DIR
os.environ["TEMP"] = TEMP_DIR
os.environ["TMP"] = TEMP_DIR

# –¢–∞–∫–∂–µ –≥–æ–≤–æ—Ä–∏–º –º–æ–¥—É–ª—é tempfile –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —ç—Ç—É –ø–∞–ø–∫—É
tempfile.tempdir = TEMP_DIR

print(f"–í—Ä–µ–º–µ–Ω–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è Playwright: {TEMP_DIR}")
load_dotenv()

# ----------------------------------------------------------------------
# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –æ—à–∏–±–æ–∫ (–∞–Ω–∞–ª–æ–≥ trace.php)
# ----------------------------------------------------------------------
TRACE_URL = "https://server.brain-project.online/trace.php"
NODE_NAME = os.getenv("NODE_NAME", "vlad_investing_crypto_news")
ALERT_EMAIL = os.getenv("ALERT_EMAIL", "vladyurjevitch@yandex.ru")

# ----------------------------------------------------------------------
# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–∞—Ä—Å–∏–Ω–≥–∞ Investing.com
# ----------------------------------------------------------------------
BASE_URL = "https://ru.investing.com/news/cryptocurrency-news"
MAX_PAGES = 999  # –ó–∞—â–∏—Ç–∞ –æ—Ç –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ (–ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ unlimited)


# ----------------------------------------------------------------------
# –§—É–Ω–∫—Ü–∏—è –æ—Ç–ø—Ä–∞–≤–∫–∏ —Ç—Ä–µ–π—Å–∞ –æ–± –æ—à–∏–±–∫–µ
# ----------------------------------------------------------------------
def send_error_trace(exc: Exception, script_name: str = "investing_crypto_news_loader.py"):
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∏—Å–∫–ª—é—á–µ–Ω–∏–∏ –Ω–∞ —Å–µ—Ä–≤–µ—Ä —Ç—Ä–µ–π—Å–æ–≤.
    """
    logs = (
        f"Node: {NODE_NAME}\n"
        f"Script: {script_name}\n"
        f"Exception: {repr(exc)}\n\n"
        f"Traceback:\n{traceback.format_exc()}"
    )
    payload = {
        "url": "cli_script",
        "node": NODE_NAME,
        "email": ALERT_EMAIL,
        "logs": logs
    }
    try:
        requests.post(TRACE_URL, data=payload, timeout=10)
    except Exception:
        # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Ç—Ä–µ–π—Å ‚Äì –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º
        pass


# ----------------------------------------------------------------------
# –ü–∞—Ä—Å–∏–Ω–≥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
# ----------------------------------------------------------------------
parser = argparse.ArgumentParser(
    description="–ó–∞–≥—Ä—É–∑—á–∏–∫ –Ω–æ–≤–æ—Å—Ç–µ–π Investing.com (–∫—Ä–∏–ø—Ç–æ, —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫) –≤ MySQL"
)
parser.add_argument("table_name", help="–ò–º—è —Ü–µ–ª–µ–≤–æ–π —Ç–∞–±–ª–∏—Ü—ã –≤ –ë–î")
parser.add_argument("host", nargs="?", default=os.getenv("DB_HOST"))
parser.add_argument("port", nargs="?", default=os.getenv("DB_PORT", "3306"))
parser.add_argument("user", nargs="?", default=os.getenv("DB_USER"))
parser.add_argument("password", nargs="?", default=os.getenv("DB_PASSWORD"))
parser.add_argument("database", nargs="?", default=os.getenv("DB_NAME"))
parser.add_argument("--max-pages", type=int, default=None,
                    help="–ú–∞–∫—Å–∏–º—É–º —Å—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ)")

args = parser.parse_args()

if not all([args.host, args.user, args.password, args.database]):
    print("‚ùå –û—à–∏–±–∫–∞: –Ω–µ —É–∫–∞–∑–∞–Ω—ã –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î")
    sys.exit(1)

# ----------------------------------------------------------------------
# –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫—É –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è SQLAlchemy
# ----------------------------------------------------------------------
SQLALCHEMY_URL = (
    f"mysql+mysqlconnector://{args.user}:{args.password}@"
    f"{args.host}:{args.port}/{args.database}"
)
engine = create_engine(SQLALCHEMY_URL, pool_recycle=3600)


# ----------------------------------------------------------------------
# –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ —Å –ø–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–æ–π –≤ –ë–î
# ----------------------------------------------------------------------
async def parse_and_save_incrementally(table_name, max_pages=None):
    """
    –ü–∞—Ä—Å–∏—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏ —Å—Ä–∞–∑—É —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ –ë–î (–ø–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω–æ)
    –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è –ø—Ä–∏ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–∏ –ø–æ—Å–ª–µ–¥–Ω–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏–ª–∏ max_pages
    """
    print("[*] –ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–µ—Ä–∞ Investing.com (headless mode)...")

    # –°–æ–∑–¥–∞—ë–º —Ç–∞–±–ª–∏—Ü—É –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
    ensure_table_exists(table_name)

    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å—Å—ã–ª–æ–∫ –û–î–ò–ù –†–ê–ó –≤ –Ω–∞—á–∞–ª–µ
    print("[*] –ó–∞–≥—Ä—É–∑–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å—Å—ã–ª–æ–∫ –∏–∑ –ë–î...")
    try:
        with engine.connect() as conn:
            existing = pd.read_sql(f"SELECT link FROM {table_name}", conn)
            existing_links = set(existing['link'].tolist()) if not existing.empty else set()
        print(f"   ‚úì –í –ë–î —É–∂–µ –µ—Å—Ç—å {len(existing_links)} –Ω–æ–≤–æ—Å—Ç–µ–π")
    except Exception as e:
        print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å—Å—ã–ª–æ–∫: {e}")
        existing_links = set()

    async with async_playwright() as p:
        # Headless-—Ä–µ–∂–∏–º —Å stealth –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
        browser = await p.chromium.launch(
            headless=True,
            args=[
                '--disable-blink-features=AutomationControlled',
                '--disable-dev-shm-usage',
                '--no-sandbox',
                '--disable-setuid-sandbox',
            ]
        )

        context = await browser.new_context(
            user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            viewport={'width': 1920, 'height': 1080},
            locale='ru-RU',
            timezone_id='Europe/Moscow',
        )

        page = await context.new_page()

        # –°–∫—Ä—ã–≤–∞–µ–º webdriver
        await page.add_init_script("""
            Object.defineProperty(navigator, 'webdriver', {
                get: () => undefined
            });
        """)

        total_parsed = 0
        total_added = 0
        page_num = 1
        max_limit = max_pages if max_pages else MAX_PAGES
        consecutive_failures = 0  # –°—á—ë—Ç—á–∏–∫ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –Ω–µ—É–¥–∞—á
        MAX_CONSECUTIVE_FAILURES = 10  # –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ—Å–ª–µ 10 –Ω–µ—É–¥–∞—á –ø–æ–¥—Ä—è–¥

        while page_num <= max_limit and consecutive_failures < MAX_CONSECUTIVE_FAILURES:
            try:
                # –§–æ—Ä–º–∏—Ä—É–µ–º URL
                if page_num == 1:
                    url = BASE_URL
                else:
                    url = f"{BASE_URL}/{page_num}"

                print(f"\nüìÑ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: {url}")

                await page.goto(url, timeout=30000)
                await page.wait_for_load_state('networkidle')
                await asyncio.sleep(2)

                # –ó–∞–∫—Ä—ã–≤–∞–µ–º cookie-–±–∞–Ω–Ω–µ—Ä –Ω–∞ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ
                if page_num == 1:
                    try:
                        accept_btn = page.locator('button:has-text("I Accept"), button:has-text("Accept")')
                        if await accept_btn.is_visible(timeout=3000):
                            await accept_btn.click()
                            print("   ‚úì Cookie-–±–∞–Ω–Ω–µ—Ä –∑–∞–∫—Ä—ã—Ç")
                            await asyncio.sleep(1)
                    except:
                        pass

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–æ–≤–æ—Å—Ç–µ–π
                selector = 'article[data-test="article-item"]'
                count = await page.locator(selector).count()

                if count == 0:
                    # –ü—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã
                    alternatives = [
                        '[data-test="article-item"]',
                        'article',
                        '.news-analysis-v2_article__wW0pT',
                    ]

                    for alt_selector in alternatives:
                        count = await page.locator(alt_selector).count()
                        if count >= 5:
                            selector = alt_selector
                            break

                    if count == 0:
                        consecutive_failures += 1
                        print(f"   ‚ö†Ô∏è  –ù–æ–≤–æ—Å—Ç–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã (–Ω–µ—É–¥–∞—á–∞ {consecutive_failures}/{MAX_CONSECUTIVE_FAILURES})")
                        page_num += 1
                        await asyncio.sleep(2)
                        continue

                print(f"   ‚úì –ù–∞–π–¥–µ–Ω–æ –Ω–æ–≤–æ—Å—Ç–µ–π: {count}")

                # –ü–∞—Ä—Å–∏–º –Ω–æ–≤–æ—Å—Ç–∏
                news_items = await page.locator(selector).all()
                page_news = []

                for idx, item in enumerate(news_items, 1):
                    try:
                        # === –ó–ê–ì–û–õ–û–í–û–ö –ò –°–°–´–õ–ö–ê ===
                        title = None
                        href = None

                        # –ü—Ä–æ–±—É–µ–º data-test
                        try:
                            title_elem = item.locator('[data-test="article-title-link"]')
                            title = await title_elem.inner_text()
                            href = await title_elem.get_attribute('href')
                        except:
                            # –ü—Ä–æ–±—É–µ–º –ø–æ href
                            try:
                                link_elem = item.locator('a[href*="/article-"]').first
                                title = await link_elem.inner_text()
                                href = await link_elem.get_attribute('href')
                            except:
                                # –õ—é–±–∞—è —Å—Å—ã–ª–∫–∞
                                try:
                                    link_elem = item.locator('a').first
                                    title = await link_elem.inner_text()
                                    href = await link_elem.get_attribute('href')
                                except:
                                    continue

                        title = title.strip()
                        if len(title) < 10:
                            continue

                        # –ü–æ–ª–Ω—ã–π URL
                        if href and not href.startswith('http'):
                            href = f"https://ru.investing.com{href}"

                        # === –î–ê–¢–ê ===
                        published_at = None
                        try:
                            date_elem = item.locator('[data-test="article-publish-date"]')
                            published_at = await date_elem.inner_text()
                        except:
                            try:
                                date_elem = item.locator('time, span[class*="date"]').first
                                published_at = await date_elem.inner_text()
                            except:
                                pass

                        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ datetime (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ –¥–ª—è –ë–î)
                        dt = datetime.datetime.now()  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
                        if published_at:
                            # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ø–∞—Ä—Å–∏–Ω–≥ "4 —á–∞—Å–∞ –Ω–∞–∑–∞–¥" -> datetime
                            # –ü–æ–∫–∞ –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ —Å—Ç—Ä–æ–∫—É
                            pass

                        # === –ò–°–¢–û–ß–ù–ò–ö ===
                        source = "Investing.com"
                        try:
                            source_elem = item.locator('[data-test="news-provider-name"]')
                            source = await source_elem.inner_text()
                        except:
                            pass

                        # === –û–ü–ò–°–ê–ù–ò–ï ===
                        description = None
                        try:
                            desc_elem = item.locator('[data-test="article-description"]')
                            description = await desc_elem.inner_text()
                        except:
                            pass

                        page_news.append({
                            'datetime': dt,
                            'title': title,
                            'source': source.strip(),
                            'description': description.strip() if description else '',
                            'link': href,
                            'published_at': published_at.strip() if published_at else ''
                        })

                    except Exception as e:
                        print(f"   ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —ç–ª–µ–º–µ–Ω—Ç–∞ {idx}: {e}")
                        continue

                # === –°–†–ê–ó–£ –°–û–•–†–ê–ù–Ø–ï–ú –í –ë–î ===
                if page_news:
                    df_page = pd.DataFrame(page_news)

                    # –§–∏–ª—å—Ç—Ä—É–µ–º –Ω–æ–≤—ã–µ (–∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ existing_links)
                    df_new = df_page[~df_page['link'].isin(existing_links)]

                    if not df_new.empty:
                        try:
                            df_new.to_sql(
                                name=table_name,
                                con=engine,
                                if_exists='append',
                                index=False,
                                chunksize=100,
                                method='multi'
                            )

                            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ —Å—Å—ã–ª–∫–∏ –≤ set, —á—Ç–æ–±—ã –Ω–µ –¥—É–±–ª–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ —Å–ª–µ–¥—É—é—â–∏—Ö —Å—Ç—Ä–∞–Ω–∏—Ü–∞—Ö
                            existing_links.update(df_new['link'].tolist())

                            total_added += len(df_new)
                            print(f"   ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ –≤ –ë–î: {len(df_new)} –∏–∑ {len(page_news)} (–Ω–æ–≤—ã–µ)")
                        except Exception as e:
                            print(f"   ‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –≤ –ë–î: {e}")
                            # –ù–µ –ø—Ä–µ—Ä—ã–≤–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥, –∏–¥—ë–º –¥–∞–ª—å—à–µ
                    else:
                        print(f"   ‚ÑπÔ∏è  –í—Å–µ {len(page_news)} –Ω–æ–≤–æ—Å—Ç–µ–π —É–∂–µ –µ—Å—Ç—å –≤ –ë–î")

                    total_parsed += len(page_news)
                    consecutive_failures = 0  # –£—Å–ø–µ—à–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ - —Å–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á—ë—Ç—á–∏–∫

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ —Å–ª–µ–¥—É—é—â–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞
                try:
                    next_exists = await page.locator(f'a[href*="/news/cryptocurrency-news/{page_num + 1}"]').count()
                    if next_exists == 0:
                        print(f"   ‚ÑπÔ∏è  –ü–æ—Å–ª–µ–¥–Ω—è—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ (–Ω–µ—Ç —Å—Å—ã–ª–∫–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É {page_num + 1})")
                        break
                except:
                    # –ï—Å–ª–∏ –Ω–µ –º–æ–∂–µ–º –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞–ª–∏—á–∏–µ —Å–ª–µ–¥—É—é—â–µ–π - —Å—á–∏—Ç–∞–µ–º –Ω–µ—É–¥–∞—á–µ–π
                    consecutive_failures += 1
                    print(
                        f"   ‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞–ª–∏—á–∏–µ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã (–Ω–µ—É–¥–∞—á–∞ {consecutive_failures}/{MAX_CONSECUTIVE_FAILURES})")

                page_num += 1
                await asyncio.sleep(2)  # –ü–∞—É–∑–∞ –º–µ–∂–¥—É —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º–∏

            except Exception as e:
                consecutive_failures += 1
                print(
                    f"   ‚ùå –û—à–∏–±–∫–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page_num}: {e} (–Ω–µ—É–¥–∞—á–∞ {consecutive_failures}/{MAX_CONSECUTIVE_FAILURES})")
                # –ù–µ –ø—Ä–µ—Ä—ã–≤–∞–µ–º –≤–µ—Å—å –ø—Ä–æ—Ü–µ—Å—Å, –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ
                page_num += 1
                await asyncio.sleep(2)
                continue

        await browser.close()

        print(f"\n{'=' * 60}")

        # –ü—Ä–∏—á–∏–Ω–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
        if consecutive_failures >= MAX_CONSECUTIVE_FAILURES:
            print(f"‚ö†Ô∏è  –û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ: {MAX_CONSECUTIVE_FAILURES} –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –Ω–µ—É–¥–∞—á")
        elif page_num > max_limit:
            print(f"‚ÑπÔ∏è  –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç —Å—Ç—Ä–∞–Ω–∏—Ü: {max_limit}")
        else:
            print(f"‚úÖ –î–æ—Å—Ç–∏–≥–Ω—É—Ç–∞ –ø–æ—Å–ª–µ–¥–Ω—è—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞")

        print(f"üìÑ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å—Ç—Ä–∞–Ω–∏—Ü: {page_num - 1}")
        print(f"üìä –°–ø–∞—Ä—Å–µ–Ω–æ –Ω–æ–≤–æ—Å—Ç–µ–π: {total_parsed}")
        print(f"üíæ –î–æ–±–∞–≤–ª–µ–Ω–æ –≤ –ë–î: {total_added}")

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π ID
        try:
            with engine.connect() as conn:
                result = conn.execute(text(f"SELECT MAX(id) FROM {table_name}"))
                max_id = result.scalar()
                print(f"üî¢ –ü–æ—Å–ª–µ–¥–Ω–∏–π ID –≤ —Ç–∞–±–ª–∏—Ü–µ: {max_id}")
        except:
            pass

        return total_added


# ----------------------------------------------------------------------
# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã —Å –∞–≤—Ç–æ–∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–Ω—ã–º ID
# ----------------------------------------------------------------------
def ensure_table_exists(table_name):
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã –∏ —Å–æ–∑–¥–∞—ë—Ç –µ—ë –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
    """
    with engine.connect() as conn:
        result = conn.execute(text(f"""
            SELECT COUNT(*) FROM information_schema.tables 
            WHERE table_schema = '{args.database}' AND table_name = '{table_name}'
        """))
        table_exists = result.scalar() > 0

    if not table_exists:
        create_query = text(f"""
        CREATE TABLE {table_name} (
            id INT AUTO_INCREMENT PRIMARY KEY,
            datetime DATETIME,
            title TEXT,
            source VARCHAR(255),
            description TEXT,
            link VARCHAR(500),
            published_at VARCHAR(100),
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE KEY unique_link (link)
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;
        """)
        with engine.connect() as conn:
            conn.execute(create_query)
            conn.commit()
        print(f"‚úÖ –¢–∞–±–ª–∏—Ü–∞ '{table_name}' —Å–æ–∑–¥–∞–Ω–∞ —Å –∞–≤—Ç–æ–∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–æ–º")
    else:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞
        with engine.connect() as conn:
            result = conn.execute(text(f"""
                SELECT COUNT(*) FROM information_schema.statistics 
                WHERE table_schema = '{args.database}' 
                AND table_name = '{table_name}' 
                AND column_name = 'link' 
                AND non_unique = 0
            """))
            has_unique = result.scalar() > 0

        if not has_unique:
            print(f"‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ: –≤ —Ç–∞–±–ª–∏—Ü–µ '{table_name}' –Ω–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ –Ω–∞ –ø–æ–ª–µ link")
            print("–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–æ–±–∞–≤–∏—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å –∫–æ–º–∞–Ω–¥–æ–π:")
            print(f"ALTER TABLE {table_name} MODIFY link VARCHAR(500), ADD UNIQUE INDEX unique_link (link);")


# ----------------------------------------------------------------------
# –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞
# ----------------------------------------------------------------------
def main():
    print(f"üöÄ –ó–∞–≥—Ä—É–∑—á–∏–∫ –Ω–æ–≤–æ—Å—Ç–µ–π Investing.com (–∫—Ä–∏–ø—Ç–æ, RU)")
    print(f"–ë–∞–∑–∞: {args.host}:{args.port}/{args.database}")
    print(f"üéØ –¶–µ–ª–µ–≤–∞—è —Ç–∞–±–ª–∏—Ü–∞: {args.table_name}")
    if args.max_pages:
        print(f"üìÑ –õ–∏–º–∏—Ç —Å—Ç—Ä–∞–Ω–∏—Ü: {args.max_pages}")
    else:
        print(f"üìÑ –õ–∏–º–∏—Ç —Å—Ç—Ä–∞–Ω–∏—Ü: –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ (–º–∞–∫—Å. {MAX_PAGES})")
    print("=" * 60)

    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ —Å –ø–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–æ–π
    total_added = asyncio.run(
        parse_and_save_incrementally(args.table_name, max_pages=args.max_pages)
    )

    print("=" * 60)
    print("üèÅ –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")

    if total_added == 0:
        print("‚ÑπÔ∏è  –í—Å–µ –Ω–æ–≤–æ—Å—Ç–∏ —É–∂–µ –±—ã–ª–∏ –≤ –ë–î")
    else:
        print(f"‚ú® –£—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω–æ {total_added} –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π")


if __name__ == "__main__":
    try:
        main()
    except SystemExit:
        raise
    except KeyboardInterrupt:
        print("\nüõë –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        sys.exit(1)
    except Exception as e:
        print(f"\n‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e!r}")
        send_error_trace(e)
        sys.exit(1)